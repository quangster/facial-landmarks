{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q onnx onnxruntime onnxscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import onnx\n",
    "import onnxruntime\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INPUT SHAPE: torch.Size([1, 3, 256, 256])\n",
      "OUTPUT SHAPE: torch.Size([1, 68, 2])\n"
     ]
    }
   ],
   "source": [
    "class MobileNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = models.get_model(name=\"mobilenet_v3_large\")\n",
    "        self.network.classifier = nn.Sequential(\n",
    "            nn.Linear(self.network.classifier[0].in_features, 512, bias=True),\n",
    "            nn.Hardswish(),\n",
    "            nn.Dropout(p=0.2, inplace=True),\n",
    "            nn.Linear(512, 136, bias=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.network(x)\n",
    "        x = x.reshape(x.size(0), 68, 2)\n",
    "        return x\n",
    "\n",
    "mobilenetv3 = MobileNet()\n",
    "# test load state dict\n",
    "mobilenetv3.load_state_dict(torch.load(\"../ckpts/mobilenetv3.pth\", weights_only=True))\n",
    "random_input = torch.randn([1, 3, 256, 256])\n",
    "output = mobilenetv3(random_input)\n",
    "print(f\"\\nINPUT SHAPE: {random_input.shape}\")\n",
    "print(f\"OUTPUT SHAPE: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenetv3.eval()\n",
    "sample_input = torch.randn(1, 3, 256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the model to ONNX format\n",
    "torch.onnx.export(\n",
    "    mobilenetv3,                   # The model to be exported\n",
    "    sample_input,            # The sample input tensor\n",
    "    \"../ckpts/mobilenetv3.onnx\",            # The output file name\n",
    "    export_params=True,      # Store the trained parameter weights inside the model file\n",
    "    opset_version=17,        # The ONNX version to export the model to\n",
    "    do_constant_folding=True,  # Whether to execute constant folding for optimization\n",
    "    input_names=['input'],     # The model's input names\n",
    "    output_names=['output'],   # The model's output names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX model output: [array([[[-0.39168403, -0.18489534],\n",
      "        [-0.37024066, -0.06099384],\n",
      "        [-0.33947164,  0.06636669],\n",
      "        [-0.29212415,  0.1807946 ],\n",
      "        [-0.21712731,  0.26600364],\n",
      "        [-0.14818606,  0.33422005],\n",
      "        [-0.08506522,  0.38997275],\n",
      "        [-0.03413018,  0.43978712],\n",
      "        [ 0.03120015,  0.45437065],\n",
      "        [ 0.10034149,  0.42534643],\n",
      "        [ 0.16026662,  0.35515857],\n",
      "        [ 0.2254807 ,  0.2908583 ],\n",
      "        [ 0.28484723,  0.21786368],\n",
      "        [ 0.345946  ,  0.13682531],\n",
      "        [ 0.38384056,  0.03233783],\n",
      "        [ 0.40671682, -0.07947797],\n",
      "        [ 0.41877228, -0.19772974],\n",
      "        [-0.3136756 , -0.29935202],\n",
      "        [-0.2650919 , -0.32679853],\n",
      "        [-0.21008322, -0.32956272],\n",
      "        [-0.1523622 , -0.3112476 ],\n",
      "        [-0.09870441, -0.28283286],\n",
      "        [ 0.05771669, -0.26997918],\n",
      "        [ 0.10144198, -0.29522717],\n",
      "        [ 0.15228482, -0.30567175],\n",
      "        [ 0.2023467 , -0.3050224 ],\n",
      "        [ 0.2558356 , -0.28021204],\n",
      "        [-0.00834219, -0.17217474],\n",
      "        [-0.01029998, -0.10936914],\n",
      "        [-0.01174965, -0.04671498],\n",
      "        [-0.01213104,  0.0175823 ],\n",
      "        [-0.07140086,  0.09165827],\n",
      "        [-0.04194185,  0.10112859],\n",
      "        [-0.01159692,  0.1073513 ],\n",
      "        [ 0.02394404,  0.10510451],\n",
      "        [ 0.05997146,  0.09934077],\n",
      "        [-0.23550108, -0.18967775],\n",
      "        [-0.19784454, -0.22189665],\n",
      "        [-0.1516047 , -0.21545163],\n",
      "        [-0.11575595, -0.16826889],\n",
      "        [-0.15559724, -0.16298926],\n",
      "        [-0.20240687, -0.16744718],\n",
      "        [ 0.09198872, -0.15625077],\n",
      "        [ 0.12676606, -0.19913848],\n",
      "        [ 0.1741126 , -0.20081875],\n",
      "        [ 0.21407275, -0.16545647],\n",
      "        [ 0.17794655, -0.14526898],\n",
      "        [ 0.13136566, -0.14408384],\n",
      "        [-0.09986028,  0.24806619],\n",
      "        [-0.06183089,  0.22714552],\n",
      "        [-0.02018419,  0.21063355],\n",
      "        [ 0.00066623,  0.21838276],\n",
      "        [ 0.02494109,  0.2140736 ],\n",
      "        [ 0.07960091,  0.23669694],\n",
      "        [ 0.13235323,  0.26773348],\n",
      "        [ 0.08191337,  0.31962317],\n",
      "        [ 0.02917471,  0.3339877 ],\n",
      "        [ 0.002117  ,  0.33273995],\n",
      "        [-0.02279802,  0.32544   ],\n",
      "        [-0.06275171,  0.2970984 ],\n",
      "        [-0.08136401,  0.24799748],\n",
      "        [-0.01795582,  0.24888341],\n",
      "        [ 0.00253735,  0.25183672],\n",
      "        [ 0.02689499,  0.25076917],\n",
      "        [ 0.11235502,  0.26599017],\n",
      "        [ 0.02704353,  0.289177  ],\n",
      "        [ 0.00213318,  0.2858172 ],\n",
      "        [-0.01996727,  0.28085905]]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import onnxruntime\n",
    "\n",
    "# Load the ONNX model\n",
    "onnx_model = onnx.load(\"../ckpts/mobilenetv3.onnx\")\n",
    "\n",
    "# Check that the model is well-formed\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "# Run inference using ONNX Runtime\n",
    "ort_session = onnxruntime.InferenceSession(\"../ckpts/mobilenetv3.onnx\")\n",
    "\n",
    "# Prepare the input\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: sample_input.numpy()}\n",
    "\n",
    "# Run the model\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "\n",
    "print(\"ONNX model output:\", ort_outs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, model_name: str = \"resnet18\", weights: str = \"DEFAULT\"):\n",
    "        super().__init__()\n",
    "        self.network = models.get_model(name=\"resnet18\", weights=weights)\n",
    "        self.network.fc = nn.Linear(self.network.fc.in_features, 136)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.network(x)\n",
    "        x = x.reshape(x.size(0), 68, 2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet18 = ResNet()\n",
    "resnet18.load_state_dict(torch.load(\"../ckpts/resnet18.pth\", weights_only=True))\n",
    "resnet18.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the model to ONNX format\n",
    "torch.onnx.export(\n",
    "    resnet18,                   # The model to be exported\n",
    "    sample_input,            # The sample input tensor\n",
    "    \"../ckpts/resnet18.onnx\",            # The output file name\n",
    "    export_params=True,      # Store the trained parameter weights inside the model file\n",
    "    opset_version=17,        # The ONNX version to export the model to\n",
    "    do_constant_folding=True,  # Whether to execute constant folding for optimization\n",
    "    input_names=['input'],     # The model's input names\n",
    "    output_names=['output'],   # The model's output names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX model output: [array([[[-0.45445412, -0.06765888],\n",
      "        [-0.43737787,  0.0323271 ],\n",
      "        [-0.40834022,  0.14212349],\n",
      "        [-0.37059885,  0.24048012],\n",
      "        [-0.30883074,  0.33653918],\n",
      "        [-0.23823655,  0.41860116],\n",
      "        [-0.1491706 ,  0.48789018],\n",
      "        [-0.05199888,  0.52036834],\n",
      "        [ 0.05197332,  0.5154389 ],\n",
      "        [ 0.14668252,  0.4961621 ],\n",
      "        [ 0.23877901,  0.4483102 ],\n",
      "        [ 0.32559776,  0.38359955],\n",
      "        [ 0.37981635,  0.30120146],\n",
      "        [ 0.4051861 ,  0.18851948],\n",
      "        [ 0.41418374,  0.07769438],\n",
      "        [ 0.4147988 , -0.04413731],\n",
      "        [ 0.40104443, -0.16021669],\n",
      "        [-0.40172106, -0.2363964 ],\n",
      "        [-0.34704244, -0.2708525 ],\n",
      "        [-0.28175843, -0.30783334],\n",
      "        [-0.20375592, -0.30759847],\n",
      "        [-0.14086582, -0.29197752],\n",
      "        [-0.03487684, -0.3070017 ],\n",
      "        [ 0.03634944, -0.34451452],\n",
      "        [ 0.1126644 , -0.3502441 ],\n",
      "        [ 0.18725513, -0.32493007],\n",
      "        [ 0.26198304, -0.2812723 ],\n",
      "        [-0.06843121, -0.22102833],\n",
      "        [-0.06567462, -0.16060603],\n",
      "        [-0.05634176, -0.1059728 ],\n",
      "        [-0.05471949, -0.04406097],\n",
      "        [-0.09943213,  0.0600745 ],\n",
      "        [-0.07382531,  0.06904998],\n",
      "        [-0.03865815,  0.07267444],\n",
      "        [-0.01688674,  0.06280883],\n",
      "        [ 0.02112619,  0.03650843],\n",
      "        [-0.30246717, -0.13154973],\n",
      "        [-0.2671017 , -0.15030737],\n",
      "        [-0.21332422, -0.1568074 ],\n",
      "        [-0.15542927, -0.15760921],\n",
      "        [-0.20932001, -0.13574389],\n",
      "        [-0.25661072, -0.12219463],\n",
      "        [ 0.05115253, -0.17640656],\n",
      "        [ 0.09669718, -0.19753906],\n",
      "        [ 0.15168527, -0.19908749],\n",
      "        [ 0.20665075, -0.1939919 ],\n",
      "        [ 0.16356537, -0.17841485],\n",
      "        [ 0.10708009, -0.1718608 ],\n",
      "        [-0.18985243,  0.25261664],\n",
      "        [-0.13707851,  0.1934245 ],\n",
      "        [-0.08606248,  0.16663864],\n",
      "        [-0.03736111,  0.16816439],\n",
      "        [ 0.00119711,  0.1572175 ],\n",
      "        [ 0.07261612,  0.17535792],\n",
      "        [ 0.15676343,  0.23105216],\n",
      "        [ 0.10816155,  0.30391553],\n",
      "        [ 0.03271832,  0.34463263],\n",
      "        [-0.01177959,  0.34905052],\n",
      "        [-0.06706844,  0.34616375],\n",
      "        [-0.13022572,  0.31819347],\n",
      "        [-0.15869617,  0.24689111],\n",
      "        [-0.07541772,  0.20170751],\n",
      "        [-0.02477394,  0.20110887],\n",
      "        [ 0.01152155,  0.1944765 ],\n",
      "        [ 0.13155991,  0.23369935],\n",
      "        [ 0.02119793,  0.2927736 ],\n",
      "        [-0.02656846,  0.29877874],\n",
      "        [-0.07533959,  0.29874545]]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import onnxruntime\n",
    "\n",
    "# Load the ONNX model\n",
    "onnx_model = onnx.load(\"../ckpts/resnet18.onnx\")\n",
    "\n",
    "# Check that the model is well-formed\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "# Run inference using ONNX Runtime\n",
    "ort_session = onnxruntime.InferenceSession(\"../ckpts/resnet18.onnx\")\n",
    "\n",
    "# Prepare the input\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: sample_input.numpy()}\n",
    "\n",
    "# Run the model\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "\n",
    "print(\"ONNX model output:\", ort_outs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "filter-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
