{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import defusedxml.ElementTree as ET\n",
    "import numpy as np\n",
    "import torch\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from PIL import Image, ImageDraw\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class LandmarksDataset(Dataset):\n",
    "    def __init__(self, data_dir, xml_file_path, transforms=None) -> None:\n",
    "        self.data_dir: str = data_dir\n",
    "        self.samples: list[dict] = self.load_data(os.path.join(self.data_dir, xml_file_path))\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample: dict = self.samples[index]\n",
    "\n",
    "        file_name = sample[\"file_name\"]\n",
    "        img_path = os.path.join(self.data_dir, file_name)\n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        box_left = sample[\"box_left\"]\n",
    "        box_top = sample[\"box_top\"]\n",
    "        box_width = sample[\"box_width\"]\n",
    "        box_height = sample[\"box_height\"]\n",
    "\n",
    "        # crop image\n",
    "        img = img.crop((box_left, box_top, box_left + box_width, box_top + box_height))\n",
    "\n",
    "        # normalize landmarks\n",
    "        landmarks = np.array(sample[\"landmarks\"]) - np.array([box_left, box_top])\n",
    "\n",
    "        if self.transforms:\n",
    "            img = np.array(img)\n",
    "            transformed = self.transforms(image=img, keypoints=landmarks)\n",
    "            img = transformed[\"image\"]\n",
    "            landmarks = transformed[\"keypoints\"]\n",
    "            _, height, width = img.shape\n",
    "            landmarks /= np.array([width, height])\n",
    "            landmarks -= 0.5\n",
    "\n",
    "        return img, torch.Tensor(landmarks)\n",
    "\n",
    "    @staticmethod\n",
    "    def annotate_landmarks(\n",
    "        img: torch.Tensor, landmarks: torch.Tensor, is_ground_truth: bool = True\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Annotate landmarks on image\n",
    "\n",
    "        Args:\n",
    "            img (torch.Tensor):\n",
    "            landmarks (torch.Tensor): normalized landmarks [-0.5, 0.5]\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: _description_\n",
    "        \"\"\"\n",
    "        img = img.clone()\n",
    "        landmarks = landmarks.clone()\n",
    "\n",
    "        _, height, width = img.shape\n",
    "        landmarks += 0.5\n",
    "        landmarks *= np.array([width, height])\n",
    "        img = img.permute(1, 2, 0).numpy()\n",
    "        img = Image.fromarray((img * 255).astype(np.uint8))\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        if is_ground_truth:\n",
    "            for x, y in landmarks:\n",
    "                draw.ellipse((x - 2, y - 2, x + 2, y + 2), fill=(0, 255, 0))\n",
    "        else:\n",
    "            for x, y in landmarks:\n",
    "                draw.ellipse((x - 2, y - 2, x + 2, y + 2), fill=(255, 0, 0))\n",
    "\n",
    "        img = np.array(img).astype(np.float32) / 255.0\n",
    "        img = ToTensorV2()(image=img)[\"image\"]\n",
    "        return img\n",
    "\n",
    "    def load_data(self, xml_file_path: str) -> list[dict]:\n",
    "        \"\"\"Load data: file_path, bbox, landmarks\n",
    "\n",
    "        Args:\n",
    "            xml_file_path (str): xml file path\n",
    "\n",
    "        Returns:\n",
    "            list[dict]: list[{\n",
    "                \"file_name\": str,\n",
    "                \"width\": int,\n",
    "                \"height\": int,\n",
    "                \"box_top\": int,\n",
    "                \"box_left\": int,\n",
    "                \"box_width\": int,\n",
    "                \"box_height\": int,\n",
    "                \"landmarks\": np.array()\n",
    "            }]\n",
    "        \"\"\"\n",
    "        images = ET.parse(xml_file_path).getroot().find(\"images\")\n",
    "        return [self.parse_image(image) for image in images]\n",
    "\n",
    "    def parse_image(self, image: ET) -> dict:\n",
    "        \"\"\"Parse ET.ElementTree to dict.\n",
    "\n",
    "        Args:\n",
    "            image (ET.ElementTree): ET.ElementTree\n",
    "\n",
    "        Returns:\n",
    "            dict: {\n",
    "                \"file_name\": str,\n",
    "                \"width\": int,\n",
    "                \"height\": int,\n",
    "                \"box_top\": int,\n",
    "                \"box_left\": int,\n",
    "                \"box_width\": int,\n",
    "                \"box_height\": int,\n",
    "                \"landmarks\": np.array()\n",
    "            }\n",
    "        \"\"\"\n",
    "        file_name = image.attrib[\"file\"]\n",
    "        width = int(image.attrib[\"width\"])\n",
    "        height = int(image.attrib[\"height\"])\n",
    "\n",
    "        box = image.find(\"box\")\n",
    "        box_top = int(box.attrib[\"top\"])\n",
    "        box_left = int(box.attrib[\"left\"])\n",
    "        box_width = int(box.attrib[\"width\"])\n",
    "        box_height = int(box.attrib[\"height\"])\n",
    "\n",
    "        landmarks = np.array([[float(part.attrib[\"x\"]), float(part.attrib[\"y\"])] for part in box])\n",
    "\n",
    "        return dict(\n",
    "            file_name=file_name,\n",
    "            width=width,\n",
    "            height=height,\n",
    "            box_top=box_top,\n",
    "            box_left=box_left,\n",
    "            box_width=box_width,\n",
    "            box_height=box_height,\n",
    "            landmarks=landmarks,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "\n",
    "transforms = A.Compose(\n",
    "    [\n",
    "        A.Resize(height=256, width=256, always_apply=True),\n",
    "        A.ToFloat(max_value=255),\n",
    "        ToTensorV2(),\n",
    "    ],\n",
    "    keypoint_params=A.KeypointParams(format=\"xy\", remove_invisible=False),\n",
    ")\n",
    "\n",
    "dataset = LandmarksDataset(\n",
    "    data_dir=\"../data/ibug_300W_large_face_landmark_dataset\",\n",
    "    xml_file_path=\"labels_ibug_300W_train.xml\",\n",
    "    transforms=transforms,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = dataset.annotate_landmarks(dataset[90][0], dataset[90][1], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(image.permute(1, 2, 0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "filter-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
